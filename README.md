# Using SciML Symbolics to Solve Perturbation Problems

## Background

[**Symbolics.jl**](https://github.com/JuliaSymbolics/Symbolics.jl) is a fast and modern Computer Algebra System (CAS) written in Julia Programming Language. It is part of the [SciML](https://sciml.ai/) ecosystem of differential equation solvers and scientific machine learning packages. While **Symbolics.jl** is primarily designed for modern scientific computing (e.g., machine learning), it is a powerful CAS and can be useful in *classic* scientific computing, like *perturbation* problems.

Perturbation methods are a collection of techniques to solve algebraic and differential equations. The target problems generally don't have a closed solution. However, they depend on a tunable parameter and have closed-form or easy solutions for some values of the parameter. The main idea is to assume a solution as a power series in the tunable parameter (say ùúÄ), such that ùúÄ = 0 corresponds to a closed solution.

We will discuss the general steps of the perturbation methods in four examples below. One hallmark of the perturbation method is the generation of long and involved intermediate equations, which are subjected to algorithmic and mechanical manipulations. Therefore, these problems are well suited for CAS. In fact, CAS softwares have been used to help with the perturbation calculations since the 1950s.

In this tutorial our goal is to show how to use Julia and **Symbolics.jl** to solve simple perturbation problems.

## Solving the Quintic

We start with the "hello world!" analog of the perturbation problems: solving the quintic (fifth-order) equations. We want to find ùë• such that ùë•‚Åµ + ùë• = 1. According to the Abel's theorem, a general quintic equation does not have a closed form solution. Of course, we can easily solve this equation numerically; for example, using the Newton's method. Here, we use the following implementation of the Newton's method:

```Julia
using Symbolics, SymbolicUtils

function solve_newton(f, x, x‚ÇÄ; abstol=1e-8, maxiter=50)
    x‚Çô = Float64(x‚ÇÄ)
    f‚Çô‚Çä‚ÇÅ = x - f / Symbolics.derivative(f, x)

    for i = 1:maxiter
        x‚Çô‚Çä‚ÇÅ = substitute(f‚Çô‚Çä‚ÇÅ, Dict(x => x‚Çô))
        if abs(x‚Çô‚Çä‚ÇÅ - x‚Çô) < abstol
            return x‚Çô‚Çä‚ÇÅ
        else
            x‚Çô = x‚Çô‚Çä‚ÇÅ
        end
    end
    return x‚Çô‚Çä‚ÇÅ
end
```

In this code, `Symbolics.derivative(eq, x)` does exactly what it names implies: it calculates the symbolic derivative of `eq` (a **Symbolics.jl** expression) with respect to `x` (a **Symbolics.jl** variable). We use `Symbolics.substitute(eq, D)` to evaluate the update formula by substituting variables or sub-expressions (defined as a dictionary `D`) in `eq`. It should be noted that `substitute` is the workhorse of our code and will be used multiple times in the rest of this tutorial. `solve_newton` is written with simplicity and clarity in mind and not performance.

Let's go back to our quintic. We can define a Symbolics variable as `@variables x` and then solve the equation as `solve_newton(x^5 + x - 1, x, 1.0)` (here, `x‚ÇÄ = 0` is our first guess). The answer is `x = 0.7549`. Now, let's see how we can solve this problem using the perturbation method.

We introduce a tuning parameter ùúÄ into our equation: ùë•‚Åµ + ùë• = 1. If ùúÄ = 1, we get our original problem. For ùúÄ = 0, the problem transforms to an easy one: ùë•‚Åµ = 1 which has a solution ùë• = 1 (and four complex solutions which we ignore here). We expand ùë• as a power series on ùúÄ:

ùë•(ùúÄ) = ùëé‚ÇÄ + ùëé‚ÇÅùúÄ + ùëé‚ÇÇùúÄ¬≤ + ùëÇ(ùúÄ¬≥)

ùëé‚ÇÄ is the solution of the easy equation, therefore ùëé‚ÇÄ = 1. Substituting into the original problem,

(1 + ùëé‚ÇÅùúÄ + ùëé‚ÇÇùúÄ¬≤)‚Åµ + ùúÄ (1 + ùëé‚ÇÅùúÄ + ùëé‚ÇÇùúÄ¬≤) - 1 = 0


Expanding the equations, we get

ùúÄ (1 + 5ùëé‚ÇÅ) + ùúÄ¬≤ (ùëé‚ÇÅ + 5ùëé‚ÇÇ + 10ùëé‚ÇÅ¬≤) + ùëÇ(ùúÄ¬≥) = 0

This equation should hold for each power of ùúÄ,

1 + 5ùëé‚ÇÅ = 0,

and

ùëé‚ÇÅ + 5ùëé‚ÇÇ + 10ùëé‚ÇÅ¬≤ = 0.


We solve the first equation to get ùëé‚ÇÅ = -1/5. Substituting in the second one and solve for ùëé‚ÇÇ:

ùëé‚ÇÇ = (-1/5 + 10(-(1/5)¬≤) / 5 = -1/25

Finally,

ùë•(ùúÄ) = 1 - ùúÄ / 5 - ùúÄ¬≤ / 25 + ùëÇ(ùúÄ¬≥)


Solving the original problem, ùë•(1) = 0.76, compared to 0.75487767 calculated numerically. We can improve the accuracy by including more terms in the expansion of ùë•. However, the calculations, while straightforward, become messy and intractable for do manually very quickly. This is why a CAS is very helpful to solve perturbation problems. So, let's see how we can do these calculations in Julia (`test_quintic` function).

Let `n = 2` be the order of the expansion. We start by defining the variables:

```Julia
  @variables @variables œµ a[1:n]        
```

Then, we define `x = 1 + a[1]*œµ + a[2]*œµ^2`. Note that in `test_quintic` we use the helper function `def_taylor` to define `x` by calling it as `x = def_taylor(œµ, a, 1)`. The next step is to substitute ùë• is the problem `y = x^5 + œµ*x - 1`. Now, `y` is

```Julia
  œµ*(1 + a‚ÇÅ*œµ + a‚ÇÇ*(œµ^2)) + (1 + a‚ÇÅ*œµ + a‚ÇÇ*(œµ^2))^5 - 1
```

Or in the expanded form (calculated as `expand(y)`):

```Julia
œµ + a‚ÇÅ*(œµ^2) + a‚ÇÇ*(œµ^3) + (a‚ÇÅ^5)*(œµ^5) + (a‚ÇÇ^5)*(œµ^10) + 5a‚ÇÅ*œµ + 5a‚ÇÇ*(œµ^2) +
10(a‚ÇÅ^2)*(œµ^2) + 10(a‚ÇÅ^3)*(œµ^3) + 5(a‚ÇÅ^4)*(œµ^4) + 10(a‚ÇÇ^2)*(œµ^4) +
10(a‚ÇÇ^3)*(œµ^6) + 5(a‚ÇÇ^4)*(œµ^8) + 20a‚ÇÅ*a‚ÇÇ*(œµ^3) + 30a‚ÇÅ*(a‚ÇÇ^2)*(œµ^5) +
20a‚ÇÅ*(a‚ÇÇ^3)*(œµ^7) + 5a‚ÇÅ*(a‚ÇÇ^4)*(œµ^9) + 30a‚ÇÇ*(a‚ÇÅ^2)*(œµ^4) + 20a‚ÇÇ*(a‚ÇÅ^3)*(œµ^5) +
5a‚ÇÇ*(a‚ÇÅ^4)*(œµ^6) + 30(a‚ÇÅ^2)*(a‚ÇÇ^2)*(œµ^6) + 10(a‚ÇÅ^2)*(a‚ÇÇ^3)*(œµ^8) +
10(a‚ÇÅ^3)*(a‚ÇÇ^2)*(œµ^7)
```

We need a way to get the coefficients of different powers of ùúÄ. Function `collect_powers(eq, x, ns)` returns the powers of `x` in expression `eq`. Argument `ns` is the range of the powers.

```Julia
function collect_powers(eq, x, ns; max_power=100)
    eq = substitute(expand(eq), Dict(x^j => 0 for j=last(ns)+1:max_power))

    eqs = []
    for i in ns
        powers = Dict(x^j => (i==j ? 1 : 0) for j=1:last(ns))
        push!(eqs, substitute(eq, powers))
    end
    eqs
end
```

For example, `collect_powers(y, œµ, 1:2)` returns `eqs = [1 + 5a‚ÇÅ, a‚ÇÅ + 5a‚ÇÇ + 10(a‚ÇÅ^2)]`. `collect_powers` uses `substitute` to find the coefficient of a given power of `x` by passing a `Dict` with all powers of `x` set to 0, except the target power which is set to 1. To find the coefficient of `œµ^2` in `y`, we can write

```julia
  substitute(expand(y), Dict(
    œµ => 0,
    œµ^2 => 1,
    œµ^3 => 0,
    œµ^4 => 0,
    œµ^5 => 0,
    œµ^6 => 0,
    œµ^7 => 0,
    œµ^8 => 0)
  )
```

The next step is find the coefficients of `œµ` in the expansion of `x`. **Symbolics.jl** has a function `Symbolics.solve_for` that can solve systems of linear equations. The system described by `eqs` does not seem linear (note `10(a‚ÇÅ^2)` in `eqs[2]`), but upon closer inspection is found to be in fact linear (this is a feature of the permutation method). We can start by solving `eqs[1]` for `a‚ÇÅ` and then substitute it in `eqs[2]` and solve for `a‚ÇÇ`.  This process is done by function `solve_coef(eqs, ps)`:

```julia
function solve_coef(eqs, ps)
    vals = Dict()

    for i = 1:length(ps)
        eq = substitute(eqs[i], vals)
        vals[ps[i]] = Symbolics.solve_for(eq ~ 0, ps[i])
    end
    vals
end
```

Here, `eqs` is an array of expressions (assumed to be equal to 0) and `ps` is an array of variables. The result is a dictionary of variable => value pairs. For example, `solve_coef(eqs, a)` is `Dict(a‚ÇÅ => -0.2,
a‚ÇÇ => -0.04)`. We can use larger values of `n` to improve the accuracy of estimations:

| n | x              |
|---|----------------|
|1  |0.8 |
|2  |0.76|
|3  |0.752|
|4  |0.752|
|5  |0.7533|
|6  |0.7543|
|7  |0.7548|
|8  |0.7550|

Remember the numerical value is 0.7549.

The two functions `collect_powers` and `solve_coef(eqs, a)` are used in all the examples in this tutorial and show the main steps in the permutation method.

## Solving the Kepler's Equation

Historically, the perturbation methods were first invented to solve orbital calculations needed to calculate the orbit of the moon and planets. In homage to this history, our second example has a celestial theme. Our goal is solve the Kepler's equation:

ùê∏ - ùëí sin(ùê∏) = ùëÄ.  

where ùëí is the *eccentricity* of the elliptical orbit, ùëÄ is the *mean anomaly*, and ùê∏ (unknown) is the *eccentric anomaly* (the angle between the position of a planet in an elliptical orbit and the point of periapsis). We want to find a function ùê∏(ùëÄ; ùëí). As the first example, it is easy to solve this problem using the Newton's method. For example, let ùëí = 0.01671 (the eccentricity of the Earth) and ùëÄ = œÄ/2. We have `solve_newton(x - e*sin(x) - M, x, M)` equals to 1.5875 (compared to œÄ/2 = 1.5708). Now, we try to solve the same problem using the perturbation techniques (see function `test_kepler`.

For ùëí = 0, ùê∏ = ùëÄ. Therefore, we can use ùëí as our perturbation parameter. For consistency, we rename it to ùúÄ. We start by defining the variables and ùë• (assuming `n = 3`):

```julia
  @variables œµ M a[1:n]
  x = def_taylor(œµ, n, M)  
```

The problem equation is `y = E - œµ * sin(E) - M`. We further simplify by substituting sin with its power series (using `expand_sin` helper function):

sin(ùê∏) = ùë• - ùë•¬≥ / 6 + ùë•‚Åµ / 120 - ùë•‚Å∑ / 5040 + ùëÇ(ùë•‚Åπ).

We follow the same algorithm as before. We collect the coefficients of the powers of ùúÄ:

```
  eqs = collect_powers(y, œµ, 1:n)
```

and then solve for `a`:

```
  vals = solve_coef(eqs, a)
```

Finally, we substitute `vals` back in `x` to get a formula to calculate `E`:

```
  sol = substitute(x, vals)
  substitute(sol, Dict(œµ => 0.01671, M => œÄ/2))
```

The result is 1.5876, compared to the numerical value of 1.5875. It is customary to order `sol` based on the powers of `M` instead of `œµ`. We can calculate this series as `collect_powers(sol, M, 0:3)
`. The result (after cleanup) is

```julia
  E(M, œµ) =
    (1 + œµ + œµ^2 + œµ^3)*M
    - (œµ + 4*œµ^2 + 10*œµ^3)*M^3/6
    + (œµ + 16*œµ^2 + 91*œµ^3)*M^5/120
```

Comparing the formula to the one for ùê∏ in the [Wikipedia article on the Kepler's equation](https://en.wikipedia.org/wiki/Kepler%27s_equation):

<img src="https://render.githubusercontent.com/render/math?math=E = \frac{1}{1-\epsilon}M-\frac{\epsilon}{(1-\epsilon)^4} \frac{M^3}{3!} %2B \frac{(9\epsilon^2 %2B  \epsilon)}{(1-\epsilon)^7}\frac{M^5}{5!}\cdots">

The first deviation is in the coefficient of ùúÄ¬≥ùëÄ‚Åµ.

## The Trajectory of a Ball!

In the first two examples, we applied the permutation method to algebraic problems. However, the main power of the permutation method is to solve differential equations (usually as ODEs, bot occasionally PDEs). Surprisingly, the main procedure developed to solve algebraic problems works well for differential equations. In fact, we will use the same two helper functions, `collect_powers` and `solve_coef`. The main difference is in the way we expand the dependent variables. For algebraic problems, the coefficients of ùúÄ are constants; whereas, for differential equations, they are functions of the dependent variable (usually time).

For the first example of how to solve an ODE, we have chosen a simple and well-behaved problem. The problem is a variation of a standard first-year physics problem: what is the trajectory of an object (say, a ball or a rocket) thrown vertically at velocity ùë£ from the surface of a planet. Assuming a  constant acceleration of gravity, ùëî, every burgeoning physicist knows the answer: ùë•(ùë°) = ùë£ùë° - ùëîùë°¬≤/2. However, what happens if ùëî is not constant? Specifically, ùëî is inversely proportional to the distant from the center of the planet. If ùë£ is large, the assumption of constant gravity does not hold. However, unless ùë£ is large compared to the escape velocity, the correction is usually small. After simplifications, the problem becomes ùë•Ãà(ùë°) = -(1 + ùúÄùë•(ùë°))‚Åª¬≤, assuming ùë•(0) = 0, and ùë•Ãá(0) = 1. Note that for ùúÄ = 0, it transforms to the standard one.

Let's start with defining the variables

```julia
  @variables œµ t y[1:n](t) ‚àÇ‚àÇy[1:n]
```

Next, we define ùë• (for `n = 3`):

```julia
  x = y[1] + y[2]*œµ + y[3]*œµ^2
```

We need the second derivative of `x`. It may seem that we can do this using `Differential(t)`; however, this action needs to wait! Instead, we define the dummy variables `‚àÇ‚àÇy` as the placeholder for the derivatives and define
```julia
  ‚àÇ‚àÇx = ‚àÇ‚àÇy[1] + ‚àÇ‚àÇy[2]*œµ + ‚àÇ‚àÇy[3]*œµ^2
```
as the second derivative of `x`. After rearrangement, our governing equation is ùë•Ãà(ùë°)(1 + ùúÄùë•(ùë°))¬≤ + 1 = 0, or

```Julia
  eq = ‚àÇ‚àÇx * (1 + œµ*x)^2 + 1
```

The next steps are the same as before (however, note that we pass `0:n-1` to `collect_powers` because the zeroth order term is needed here)

```julia
  eqs = collect_powers(eq, œµ, 0:n-1)
  vals = solve_coef(eqs, ‚àÇ‚àÇy)
```

At this stage,

```julia
  vals = Dict(
    ‚àÇ‚àÇy‚ÇÅ => -1.0,
    ‚àÇ‚àÇy‚ÇÇ => 2.0y‚ÇÅ(t),
    ‚àÇ‚àÇy‚ÇÉ => 2.0y‚ÇÇ(t) - (3.0(y‚ÇÅ(t)^2))
  )
```

Our system of ODEs is forming. Note the triangular form of the relationship. This is time to convert `‚àÇ‚àÇ`s to the correct **Symbolics.jl** form:

```julia
  D = Differential(t)
  subs = Dict(‚àÇ‚àÇy[i] => D(D(y[i])) for i = 1:n)
  eqs = [substitute(first(v), subs) ~ substitute(last(v), subs) for v in vals]
```

Now, `eqs` becomes

```julia
  [Differential(t)(Differential(t)(y‚ÇÅ(t))) ~ -1.0,
   Differential(t)(Differential(t)(y‚ÇÇ(t))) ~ 2.0y‚ÇÅ(t),
   Differential(t)(Differential(t)(y‚ÇÉ(t))) ~ 2.0y‚ÇÇ(t) - (3.0(y‚ÇÅ(t)^2))]
```

We are nearly there! From this point on, the rest is standard ODE solving procedures. Potentially we can use a symbolic ODE solver to find a closed form solution to this problem. However, **Symbolics.jl** currently does not support this functionality. Instead, we solve the problem numerically. We form an `ODESystem`, lower the order (convert second derivatives to first), generate an `ODEProblem` (after passing the correct initial conditions), and, finally, solve it.

```Julia
  using ModelingToolkit, DifferentialEquations

  sys = ODESystem(eqs, t)
  sys = ode_order_lowering(sys)
  prob = ODEProblem(sys, [1.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0, 5.0))
  sol = solve(prob; dtmax=0.01)
```

The solution to the problem can be written as

```julia
  X = œµ -> sol[y[1]] .+ sol[y[2]] * œµ .+ sol[y[3]] * œµ^2
```

The following figure is generated by running
```julia
  using Plots

  plot(sol.t, hcat([X(œµ) for œµ = 0.0:0.1:0.5]...))    
```

and shows the trajectories for a range of `œµ`:

![](figures/rocket.png)

As expected, the higher `œµ` is (less effective gravity), the object goes higher and stays up for a longer duration. Of course, we could have solved the problem directly using as ODE solver. One of the benefits of the perturbation method is that we need to run the ODE solver only once and then can just calculate the answer for different values of `œµ`; whereas, if we were using direct method, we needed to run the solver once for each value of `œµ`.

## A Weakly Nonlinear Oscillator

For our final example, we have chosen a simple example from a very important class of problems, the nonlinear oscillators. As we will see, perturbation theory has difficulty providing a good solution to this problem, but the process is instructive. This example follows closely chapter 7.6 of *Nonlinear Dynamics and Chaos* by Steven Strogatz.

The problem is to solve ùë•Ãà(ùë°) + 2ùúÄùë•Ãá + ùë• = 0, assuming ùë•(0) = 0, and ùë•Ãá(0) = 1. If ùúÄ = 0, the problem reduces to the simple linear harmonic oscillator with the exact solution ùë•(t) = sin(ùë°). We follow the same steps as the previous example.

```julia
  @variables œµ t y[1:n](t) ‚àÇy[1:n] ‚àÇ‚àÇy[1:n] # n = 3
  x = y[1] + y[2]*œµ + y[3]*œµ^2
  ‚àÇx = ‚àÇy[1] + ‚àÇy[2]*œµ + ‚àÇy[3]*œµ^2
  ‚àÇ‚àÇx = ‚àÇ‚àÇy[1] + ‚àÇ‚àÇy[2]*œµ + ‚àÇ‚àÇy[3]*œµ^2
```

Note that now we also need the first derivative terms. Continuing,

```julia
  eq = ‚àÇ‚àÇx + 2*œµ*‚àÇx + x
  eqs = collect_powers(eq, œµ, 0:n-1)
  vals = solve_coef(eqs, ‚àÇ‚àÇy)
```

Let's inspect `vals`:

```julia
  vals = Dict(
    ‚àÇ‚àÇy‚ÇÅ => -y‚ÇÅ(t),
    ‚àÇ‚àÇy‚ÇÇ => -2.0‚àÇy‚ÇÅ - y‚ÇÇ(t),
    ‚àÇ‚àÇy‚ÇÉ => -2.0‚àÇy‚ÇÇ - y‚ÇÉ(t))
  )
```

Next, we need to replace `‚àÇ`s and `‚àÇ‚àÇ`s with their **Symbolics.jl** counterparts:

```julia
  D = Differential(t)
  subs1 = Dict(‚àÇy[i] => D(y[i]) for i = 1:n)
  subs2 = Dict(‚àÇ‚àÇy[i] => D(D(y[i])) for i = 1:n)
  subs = subs1 ‚à™ subs2
  eqs = [substitute(first(v), subs) ~ substitute(last(v), subs) for v in vals]
```

We continue with converting to an `ODEProblem`, solving it, and finally plot the results against the exact solution to the original problem.

```julia
  sys = ODESystem(eqs, t)
  sys = ode_order_lowering(sys)
  prob = ODEProblem(sys, [1.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0, 50.0))
  sol = solve(prob; dtmax=0.01)

  T = sol.t
  X = œµ -> sol[y[1]] .+ sol[y[2]] * œµ .+ sol[y[3]] * œµ^2
  Y = œµ -> exp.(-œµ*T) .* sin.(sqrt(1 - œµ^2)*T) / sqrt(1 - œµ^2)    # exact solution

  plot(sol.t, [Y(0.1), X(0.1)])
```

The result is (compare to Figure 7.6.2 in *Nonlinear Dynamics and Chaos*)

![](figures/oscillator.png)

The two curves fit well for the first couple of cycles, but then the perturbation method curve diverges from the true solution. The main reason is that the problem has two or more time-scales.
